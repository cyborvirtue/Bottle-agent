#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åµŒå…¥å®¢æˆ·ç«¯æ¨¡å—
æ”¯æŒOpenAIã€HuggingFaceç­‰å¤šç§åµŒå…¥æ¨¡å‹
"""

from openai import OpenAI
import numpy as np
from typing import List, Dict, Any
import logging
import time
import os

# HuggingFaceæ”¯æŒ
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    print("âš ï¸  sentence-transformersæœªå®‰è£…ï¼Œå°†æ— æ³•ä½¿ç”¨æœ¬åœ°åµŒå…¥æ¨¡å‹")


class EmbeddingClient:
    """åµŒå…¥å®¢æˆ·ç«¯"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.embedding_config = config["embedding"]
        self.provider = self.embedding_config["provider"]
        self.model_name = self.embedding_config["model"]
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        if self.provider == "openai":
            self._init_openai()
        elif self.provider == "huggingface":
            self._init_huggingface()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åµŒå…¥æä¾›å•†: {self.provider}")
    
    def _init_openai(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        api_key = self.embedding_config.get("api_key")
        if not api_key:
            raise ValueError("OpenAI APIå¯†é’¥æœªé…ç½®")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client_kwargs = {
            "api_key": api_key
        }
        
        # è®¾ç½®è‡ªå®šä¹‰base_urlï¼ˆå¦‚æœæœ‰ï¼‰
        if self.embedding_config.get("base_url"):
            client_kwargs["base_url"] = self.embedding_config["base_url"]
        
        self.openai_client = OpenAI(**client_kwargs)
    
    def _init_huggingface(self):
        """åˆå§‹åŒ–HuggingFaceå®¢æˆ·ç«¯"""
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            raise ValueError("sentence-transformersåº“æœªå®‰è£…")
        
        try:
            print(f"ğŸ¤— åŠ è½½HuggingFaceæ¨¡å‹: {self.model_name}")
            self.hf_model = SentenceTransformer(self.model_name)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            raise ValueError(f"åŠ è½½HuggingFaceæ¨¡å‹å¤±è´¥: {e}")
    
    def embed_text(self, text: str) -> np.ndarray:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„åµŒå…¥
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            åµŒå…¥å‘é‡
        """
        if self.provider == "openai":
            return self._embed_openai([text])[0]
        elif self.provider == "huggingface":
            return self._embed_huggingface([text])[0]
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åµŒå…¥æä¾›å•†: {self.provider}")
    
    def embed_texts(self, texts: List[str]) -> List[np.ndarray]:
        """ç”Ÿæˆå¤šä¸ªæ–‡æœ¬çš„åµŒå…¥
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []
        
        if self.provider == "openai":
            return self._embed_openai(texts)
        elif self.provider == "huggingface":
            return self._embed_huggingface(texts)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åµŒå…¥æä¾›å•†: {self.provider}")
    
    def _embed_openai(self, texts: List[str]) -> List[np.ndarray]:
        """ä½¿ç”¨OpenAIç”ŸæˆåµŒå…¥
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        embeddings = []
        batch_size = 100  # OpenAI APIæ‰¹å¤„ç†å¤§å°é™åˆ¶
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            
            try:
                # è°ƒç”¨OpenAI API
                response = self.openai_client.embeddings.create(
                    model=self.model_name,
                    input=batch,
                    encoding_format="float"
                )
                
                # æå–åµŒå…¥å‘é‡
                batch_embeddings = [
                    np.array(item.embedding) 
                    for item in response.data
                ]
                
                embeddings.extend(batch_embeddings)
                
                # é¿å…APIé™åˆ¶
                if i + batch_size < len(texts):
                    time.sleep(0.1)
            
            except Exception as e:
                logging.error(f"OpenAIåµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
                raise
        
        return embeddings
    
    def _embed_huggingface(self, texts: List[str]) -> List[np.ndarray]:
        """ä½¿ç”¨HuggingFaceç”ŸæˆåµŒå…¥
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        try:
            # ç”ŸæˆåµŒå…¥
            embeddings = self.hf_model.encode(
                texts,
                convert_to_numpy=True,
                show_progress_bar=len(texts) > 10
            )
            
            # è½¬æ¢ä¸ºåˆ—è¡¨
            return [embedding for embedding in embeddings]
        
        except Exception as e:
            logging.error(f"HuggingFaceåµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def get_embedding_dimension(self) -> int:
        """è·å–åµŒå…¥å‘é‡ç»´åº¦
        
        Returns:
            åµŒå…¥å‘é‡ç»´åº¦
        """
        if self.provider == "openai":
            # OpenAIæ¨¡å‹çš„ç»´åº¦
            model_dimensions = {
                "text-embedding-ada-002": 1536,
                "text-embedding-3-small": 1536,
                "text-embedding-3-large": 3072
            }
            return model_dimensions.get(self.model_name, 1536)
        
        elif self.provider == "huggingface":
            # é€šè¿‡ç”Ÿæˆä¸€ä¸ªæµ‹è¯•åµŒå…¥æ¥è·å–ç»´åº¦
            test_embedding = self.embed_text("test")
            return len(test_embedding)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åµŒå…¥æä¾›å•†: {self.provider}")
    
    def compute_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """è®¡ç®—ä¸¤ä¸ªåµŒå…¥å‘é‡çš„ç›¸ä¼¼åº¦
        
        Args:
            embedding1: åµŒå…¥å‘é‡1
            embedding2: åµŒå…¥å‘é‡2
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        """
        # å½’ä¸€åŒ–å‘é‡
        norm1 = np.linalg.norm(embedding1)
        norm2 = np.linalg.norm(embedding2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = np.dot(embedding1, embedding2) / (norm1 * norm2)
        return float(similarity)
    
    def find_most_similar(self, query_embedding: np.ndarray, 
                         candidate_embeddings: List[np.ndarray], 
                         top_k: int = 5) -> List[tuple]:
        """æ‰¾åˆ°æœ€ç›¸ä¼¼çš„åµŒå…¥å‘é‡
        
        Args:
            query_embedding: æŸ¥è¯¢åµŒå…¥å‘é‡
            candidate_embeddings: å€™é€‰åµŒå…¥å‘é‡åˆ—è¡¨
            top_k: è¿”å›çš„æœ€ç›¸ä¼¼å‘é‡æ•°é‡
            
        Returns:
            (ç´¢å¼•, ç›¸ä¼¼åº¦åˆ†æ•°)çš„åˆ—è¡¨ï¼ŒæŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
        """
        similarities = []
        
        for i, candidate in enumerate(candidate_embeddings):
            similarity = self.compute_similarity(query_embedding, candidate)
            similarities.append((i, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        return similarities[:top_k]